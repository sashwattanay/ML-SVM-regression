{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e8426a-e5a9-4e7a-96e9-e134c7a51fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Step 1: Load the California housing dataset\n",
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e250e3b1-6315-4e68-be22-917339004a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data: <class 'sklearn.utils._bunch.Bunch'>\n",
      "Keys in data: ['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the type and structure of the loaded data\n",
    "print(f\"Type of data: {type(data)}\")\n",
    "print(f\"Keys in data: {list(data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb1c269-0f05-490e-9a59-66f7e540139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Names:\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the value for a single key: 'feature_names'\n",
    "print(\"\\nFeature Names:\")\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293fffa0-5697-478c-949b-a9b90300d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset structure:\n",
      "Shape of data (features): (20640, 8)\n",
      "Shape of target: (20640,)\n",
      "\n",
      "First 5 rows of data (features):\n",
      "[[ 8.32520000e+00  4.10000000e+01  6.98412698e+00  1.02380952e+00\n",
      "   3.22000000e+02  2.55555556e+00  3.78800000e+01 -1.22230000e+02]\n",
      " [ 8.30140000e+00  2.10000000e+01  6.23813708e+00  9.71880492e-01\n",
      "   2.40100000e+03  2.10984183e+00  3.78600000e+01 -1.22220000e+02]\n",
      " [ 7.25740000e+00  5.20000000e+01  8.28813559e+00  1.07344633e+00\n",
      "   4.96000000e+02  2.80225989e+00  3.78500000e+01 -1.22240000e+02]\n",
      " [ 5.64310000e+00  5.20000000e+01  5.81735160e+00  1.07305936e+00\n",
      "   5.58000000e+02  2.54794521e+00  3.78500000e+01 -1.22250000e+02]\n",
      " [ 3.84620000e+00  5.20000000e+01  6.28185328e+00  1.08108108e+00\n",
      "   5.65000000e+02  2.18146718e+00  3.78500000e+01 -1.22250000e+02]]\n",
      "\n",
      "First 5 target values (median house values):\n",
      "[4.526 3.585 3.521 3.413 3.422]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the structure of the dataset\n",
    "print(\"\\nDataset structure:\")\n",
    "print(f\"Shape of data (features): {data['data'].shape}\")\n",
    "print(f\"Shape of target: {data['target'].shape}\")\n",
    "\n",
    "# Display the first few rows of data and target\n",
    "print(\"\\nFirst 5 rows of data (features):\")\n",
    "print(data['data'][:5])\n",
    "\n",
    "print(\"\\nFirst 5 target values (median house values):\")\n",
    "print(data['target'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c0944d-d149-4224-bdcd-962685b2522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the features DataFrame:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "\n",
      "First 5 rows of the target DataFrame:\n",
      "   MedianHouseValue\n",
      "0             4.526\n",
      "1             3.585\n",
      "2             3.521\n",
      "3             3.413\n",
      "4             3.422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to Pandas DataFrame for better readability\n",
    "features_df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "target_df = pd.DataFrame(data['target'], columns=['MedianHouseValue'])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"\\nFirst 5 rows of the features DataFrame:\")\n",
    "print(features_df.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of the target DataFrame:\")\n",
    "print(target_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd25564-0833-48ef-8adf-836b8c372470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in features:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in target:\n",
      "MedianHouseValue    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for missing values in features and target\n",
    "print(\"\\nMissing values in features:\")\n",
    "print(features_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in target:\")\n",
    "print(target_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87164e6a-a259-45e4-b28c-be93861bb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the scaled features DataFrame:\n",
      "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597  1.052548   \n",
      "1  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512  1.043185   \n",
      "2  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843  1.038503   \n",
      "3  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329  1.038503   \n",
      "4 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616  1.038503   \n",
      "\n",
      "   Longitude  \n",
      "0  -1.327835  \n",
      "1  -1.322844  \n",
      "2  -1.332827  \n",
      "3  -1.337818  \n",
      "4  -1.337818  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_df)\n",
    "\n",
    "# Convert scaled features back to DataFrame for readability\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features_df.columns)\n",
    "\n",
    "# Display the first few rows of the scaled features DataFrame\n",
    "print(\"\\nFirst 5 rows of the scaled features DataFrame:\")\n",
    "print(scaled_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c683a9-8621-4bab-8ee4-3a3dba3d4c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size (features): (16512, 8)\n",
      "Testing set size (features): (4128, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_df, target_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining set size (features):\", X_train.shape)\n",
    "print(\"Testing set size (features):\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d532ab3-fea1-403a-913d-b4527f91372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled training set size: (2000, 8)\n",
      "Sampled training set size: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Randomly sample 2,000 instances from the training set\n",
    "sample_size = 2000\n",
    "X_train_sample = X_train.sample(n=sample_size, random_state=42)\n",
    "y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "print(f\"Sampled training set size: {X_train_sample.shape}\")\n",
    "print(f\"Sampled training set size: {y_train_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea981f7-b362-4f62-bc9b-3feabd44de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best parameters: {'C': 14.25044568707964, 'epsilon': 0.32171107608941096, 'kernel': 'rbf'}\n",
      "Best cross-validation RMSE: 0.6143\n",
      "\n",
      "Performance of all hyperparameter combinations:\n",
      "      param_C param_epsilon param_kernel  mean_test_score\n",
      "17  14.250446      0.321711          rbf        -0.614312\n",
      "16   4.467293      0.401061          rbf        -0.623756\n",
      "1    16.59382       0.60685          rbf        -0.629571\n",
      "3     13.0223      0.718073          rbf        -0.637105\n",
      "19  20.391693      0.785133          rbf        -0.646457\n",
      "4    2.128232      0.731999          rbf        -0.660818\n",
      "26   1.312728      0.433401       linear        -1.154285\n",
      "5    5.246782      0.191825       linear        -1.163311\n",
      "12  10.009985      0.023265       linear        -1.165679\n",
      "2     4.11989      0.068084       linear        -1.165827\n",
      "23   8.773546      0.281349       linear        -1.170434\n",
      "11   1.929008      0.617545       linear        -1.181115\n",
      "18   5.158833        0.5777       linear        -1.185450\n",
      "6    13.34963      0.621653       linear        -1.193692\n",
      "25   3.818484      0.812197       linear        -1.229119\n",
      "13  20.312641      0.818397       linear        -1.235523\n",
      "24  12.735023      0.975255       linear        -1.246165\n",
      "10    8.64924      0.993231       linear        -1.247169\n",
      "22  11.416685      0.971172       linear        -1.250468\n",
      "27   4.974314      0.015522         poly        -1.504291\n",
      "14   1.319325      0.240894         poly        -1.615748\n",
      "8    8.997219      0.056666         poly        -2.623970\n",
      "20   8.903005      0.936659         poly        -3.058522\n",
      "0    8.490802      0.960714         poly        -3.172015\n",
      "7      9.6389      0.301229         poly        -3.195414\n",
      "29  16.425407      0.084045         poly        -3.378322\n",
      "28   4.976848      0.721342         poly        -3.390416\n",
      "9     10.1214      0.795176         poly        -3.737712\n",
      "15   14.66527      0.619997         poly        -3.802733\n",
      "21  19.437485      0.098493         poly        -3.811552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_distributions = {\n",
    "    'C': uniform(1, 20),          # C values between 1 and 21\n",
    "    'epsilon': uniform(0.01, 1),  # Epsilon values between 0.01 and 1.01\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Initialize the SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Define a custom RMSE scoring function\n",
    "def rmse_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    return -rmse  # Negate to align with scikit-learn's \"greater_is_better=False\"\n",
    "\n",
    "# Set up RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svr,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,                    # Number of random combinations to try\n",
    "    cv=5,                         # 5-fold cross-validation\n",
    "    scoring=rmse_scorer,          # Use custom RMSE scorer\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1                     # Use all available cores\n",
    ")\n",
    "\n",
    "# Perform random search on the sampled dataset\n",
    "random_search.fit(X_train_sample, y_train_sample.values.ravel())\n",
    "\n",
    "# Display the best parameters and the best score\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation RMSE: {-random_search.best_score_:.4f}\")\n",
    "\n",
    "# Create a DataFrame to show the performance of all hyperparameter combinations\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# Extract and display relevant information\n",
    "results_df = results_df[['param_C', 'param_epsilon', 'param_kernel', 'mean_test_score']]\n",
    "\n",
    "print(\"\\nPerformance of all hyperparameter combinations:\")\n",
    "print(results_df.sort_values(by='mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e074017d-7229-4691-b59d-9188d951e480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVR Model RMSE: 0.5672\n",
      "Final SVR Model MAPE: 20.40%\n",
      "Final SVR Model NRMSE: 0.1170\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Initialize the SVR model with the best hyperparameters\n",
    "final_svr_model = SVR(C=10, epsilon=0.1, kernel='rbf')\n",
    "\n",
    "# Train the model on the full training set\n",
    "final_svr_model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_final = final_svr_model.predict(X_test)\n",
    "\n",
    "# Compute Root Mean Squared Error (RMSE)\n",
    "rmse_final = np.sqrt(mean_squared_error(y_test, y_pred_final))\n",
    "\n",
    "# Compute Mean Absolute Percentage Error (MAPE)\n",
    "mape_final = np.mean(np.abs((y_test.values.ravel() - y_pred_final) / y_test.values.ravel())) * 100\n",
    "\n",
    "# Compute Normalized RMSE (NRMSE)\n",
    "nrmse_final = rmse_final / (y_test.max().values[0] - y_test.min().values[0])\n",
    "\n",
    "print(f\"Final SVR Model RMSE: {rmse_final:.4f}\")\n",
    "print(f\"Final SVR Model MAPE: {mape_final:.2f}%\")\n",
    "print(f\"Final SVR Model NRMSE: {nrmse_final:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
